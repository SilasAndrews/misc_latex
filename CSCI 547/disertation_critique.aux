\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{plainnat}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\citation{2016:lungberg}
\citation{2016:Ribeioro}
\citation{2007:zaidan}
\citation{breiman2001random}
\citation{zhou2018diverse}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Works}{2}{section.2}\protected@file@percent }
\newlabel{sec:related works}{{2}{2}{}{section.2}{}}
\newlabel{sec:related works@cref}{{[section][2][]2}{[1][2][]2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Explainable Models}{2}{subsection.2.1}\protected@file@percent }
\citation{goodfellow2014generative}
\citation{kurakin2016adversarial}
\citation{lipton2018mythos}
\citation{lewis1982using}
\citation{miller2019explanation}
\citation{bengio2013representation}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Ensemble and Adversarial Methods}{3}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Human Centered Interpretability Measures}{3}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Interpretable Representations}{4}{subsection.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Right for the Right Reasons Algorithm}{4}{section.3}\protected@file@percent }
\newlabel{sec:RRR alg}{{3}{4}{Interpretable Representations}{section.3}{}}
\newlabel{sec:RRR alg@cref}{{[section][3][]3}{[1][4][]4}}
\newlabel{fn:1}{{1}{4}{Interpretable Representations}{equation.3.1}{}}
\newlabel{fn:1@cref}{{[equation][1][]1}{[1][4][]4}}
\newlabel{fn:2}{{2}{5}{Interpretable Representations}{equation.3.2}{}}
\newlabel{fn:2@cref}{{[equation][2][]2}{[1][5][]5}}
\newlabel{fn:3}{{3}{5}{Interpretable Representations}{equation.3.3}{}}
\newlabel{fn:3@cref}{{[equation][3][]3}{[1][5][]5}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Algorithm Experiments}{5}{section.4}\protected@file@percent }
\newlabel{sec:alg exp}{{4}{5}{Interpretable Representations}{section.4}{}}
\newlabel{sec:alg exp@cref}{{[section][4][]4}{[1][5][]5}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Interpretability with Human's Study}{6}{section.5}\protected@file@percent }
\newlabel{sec:explainability}{{5}{6}{Interpretable Representations}{section.5}{}}
\newlabel{sec:explainability@cref}{{[section][5][]5}{[1][6][]6}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Test on four 2D toy data sets. Notice the success of the usual algorithms of Random Restarts and NCL, and how they compare to $\lambda = 10^{-4}$.\relax }}{7}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:1}{{1}{7}{Test on four 2D toy data sets. Notice the success of the usual algorithms of Random Restarts and NCL, and how they compare to $\lambda = 10^{-4}$.\relax }{figure.caption.1}{}}
\newlabel{fig:1@cref}{{[figure][1][]1}{[1][6][]7}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Testing popular machine learning models and LIT with an 8D data set with four 2D characteristics embedded. Notice that each traditional model learns a combination of all the rules, but LIT is forced to learn one model at a time.\relax }}{8}{figure.caption.2}\protected@file@percent }
\newlabel{fig:2}{{2}{8}{Testing popular machine learning models and LIT with an 8D data set with four 2D characteristics embedded. Notice that each traditional model learns a combination of all the rules, but LIT is forced to learn one model at a time.\relax }{figure.caption.2}{}}
\newlabel{fig:2@cref}{{[figure][2][]2}{[1][6][]8}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \relax }}{8}{figure.caption.3}\protected@file@percent }
\newlabel{fig:3}{{3}{8}{\relax }{figure.caption.3}{}}
\newlabel{fig:3@cref}{{[figure][3][]3}{[1][7][]8}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Contributions}{9}{section.6}\protected@file@percent }
\newlabel{sec:contributions}{{6}{9}{Interpretable Representations}{section.6}{}}
\newlabel{sec:contributions@cref}{{[section][6][]6}{[1][9][]9}}
\bibdata{disertation_critique}
\bibcite{bengio2013representation}{{1}{2013}{{Bengio et~al.}}{{Bengio, Courville, and Vincent}}}
\bibcite{breiman2001random}{{2}{2001}{{Breiman}}{{}}}
\bibcite{goodfellow2014generative}{{3}{2014}{{Goodfellow et~al.}}{{Goodfellow, Pouget-Abadie, Mirza, Xu, Warde-Farley, Ozair, Courville, and Bengio}}}
\bibcite{kurakin2016adversarial}{{4}{2016}{{Kurakin et~al.}}{{Kurakin, Goodfellow, and Bengio}}}
\bibcite{lewis1982using}{{5}{1982}{{Lewis}}{{}}}
\bibcite{lipton2018mythos}{{6}{2018}{{Lipton}}{{}}}
\bibcite{2016:lungberg}{{7}{2016}{{Lundberg and Lee}}{{}}}
\bibcite{miller2019explanation}{{8}{2019}{{Miller}}{{}}}
\bibcite{2016:Ribeioro}{{9}{2016}{{Ribeiro et~al.}}{{Ribeiro, Singh, and Guestrin}}}
\bibcite{2007:zaidan}{{10}{2007}{{Zaidan et~al.}}{{Zaidan, Eisner, and Piatko}}}
\bibcite{zhou2018diverse}{{11}{2018}{{Zhou et~al.}}{{Zhou, Wang, and Bilmes}}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusion}{10}{section.7}\protected@file@percent }
\newlabel{sec:conc}{{7}{10}{Interpretable Representations}{section.7}{}}
\newlabel{sec:conc@cref}{{[section][7][]7}{[1][9][]10}}
\gdef \@abspage@last{11}
