\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{plainnat}
\citation{ross2017right}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\citation{2016:lungberg}
\citation{2016:Ribeioro}
\citation{2007:zaidan}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Works}{2}{section.2}\protected@file@percent }
\newlabel{sec:related works}{{2}{2}{}{section.2}{}}
\newlabel{sec:related works@cref}{{[section][2][]2}{[1][2][]2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Explainable Models}{2}{subsection.2.1}\protected@file@percent }
\citation{breiman2001random}
\citation{zhou2018diverse}
\citation{goodfellow2014generative}
\citation{kurakin2016adversarial}
\citation{lipton2018mythos}
\citation{lewis1982using}
\citation{miller2019explanation}
\citation{bengio2013representation}
\citation{chen2016infogan}
\citation{olah2017feature}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Ensemble and Adversarial Methods}{3}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Human Centered Interpretability Measures}{3}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Interpretable Representations}{4}{subsection.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Right for the Right Reasons Algorithm}{4}{section.3}\protected@file@percent }
\newlabel{sec:RRR alg}{{3}{4}{Interpretable Representations}{section.3}{}}
\newlabel{sec:RRR alg@cref}{{[section][3][]3}{[1][4][]4}}
\newlabel{fn:1}{{1}{4}{Interpretable Representations}{equation.3.1}{}}
\newlabel{fn:1@cref}{{[equation][1][]1}{[1][4][]4}}
\newlabel{fn:2}{{2}{5}{Interpretable Representations}{equation.3.2}{}}
\newlabel{fn:2@cref}{{[equation][2][]2}{[1][5][]5}}
\newlabel{fn:3}{{3}{5}{Interpretable Representations}{equation.3.3}{}}
\newlabel{fn:3@cref}{{[equation][3][]3}{[1][5][]5}}
\citation{ross2017right}
\citation{ross2017right}
\citation{ross2017right}
\citation{ross2017right}
\@writefile{toc}{\contentsline {section}{\numberline {4}Algorithm Experiments}{6}{section.4}\protected@file@percent }
\newlabel{sec:alg exp}{{4}{6}{Interpretable Representations}{section.4}{}}
\newlabel{sec:alg exp@cref}{{[section][4][]4}{[1][6][]6}}
\citation{hinton2006reducing}
\citation{kingma2013auto}
\citation{chen2018isolating}
\citation{chen2016infogan}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Test on four 2D toy data sets as presented in \cite  {ross2017right}. Notice the success of the usual algorithms of Random Restarts and NCL, and how they compare to $\lambda = 10^{-4}$.\relax }}{7}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:1}{{1}{7}{Test on four 2D toy data sets as presented in \cite {ross2017right}. Notice the success of the usual algorithms of Random Restarts and NCL, and how they compare to $\lambda = 10^{-4}$.\relax }{figure.caption.1}{}}
\newlabel{fig:1@cref}{{[figure][1][]1}{[1][6][]7}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Interpretability with Human's Study}{7}{section.5}\protected@file@percent }
\newlabel{sec:explainability}{{5}{7}{Interpretable Representations}{section.5}{}}
\newlabel{sec:explainability@cref}{{[section][5][]5}{[1][7][]7}}
\citation{ross2017right}
\citation{ross2017right}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Testing popular machine learning models and LIT with an 8D data set with four 2D characteristics embedded, as presented in \cite  {ross2017right}. Notice that each traditional model learns a combination of all the rules, but LIT is forced to learn one model at a time.\relax }}{8}{figure.caption.2}\protected@file@percent }
\newlabel{fig:2}{{2}{8}{Testing popular machine learning models and LIT with an 8D data set with four 2D characteristics embedded, as presented in \cite {ross2017right}. Notice that each traditional model learns a combination of all the rules, but LIT is forced to learn one model at a time.\relax }{figure.caption.2}{}}
\newlabel{fig:2@cref}{{[figure][2][]2}{[1][6][]8}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The results from the human test on different data sets as presented in \cite  {ross2017right}. The mean squared error (MSE) measures the AE's error reconstructing inputs not seen during training. DCI and MIG are measurements for disentanglement, the higher the number the better the process. Disregard the references in the table, those are an artifact of the thesis it was taken from.\relax }}{9}{figure.caption.3}\protected@file@percent }
\newlabel{fig:3}{{3}{9}{The results from the human test on different data sets as presented in \cite {ross2017right}. The mean squared error (MSE) measures the AE's error reconstructing inputs not seen during training. DCI and MIG are measurements for disentanglement, the higher the number the better the process. Disregard the references in the table, those are an artifact of the thesis it was taken from.\relax }{figure.caption.3}{}}
\newlabel{fig:3@cref}{{[figure][3][]3}{[1][8][]9}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Contributions}{9}{section.6}\protected@file@percent }
\newlabel{sec:contributions}{{6}{9}{Interpretable Representations}{section.6}{}}
\newlabel{sec:contributions@cref}{{[section][6][]6}{[1][9][]9}}
\bibdata{disertation_critique}
\bibcite{bengio2013representation}{{1}{2013}{{Bengio et~al.}}{{Bengio, Courville, and Vincent}}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusion}{10}{section.7}\protected@file@percent }
\newlabel{sec:conc}{{7}{10}{Interpretable Representations}{section.7}{}}
\newlabel{sec:conc@cref}{{[section][7][]7}{[1][10][]10}}
\bibcite{breiman2001random}{{2}{2001}{{Breiman}}{{}}}
\bibcite{chen2018isolating}{{3}{2018}{{Chen et~al.}}{{Chen, Li, Grosse, and Duvenaud}}}
\bibcite{chen2016infogan}{{4}{2016}{{Chen et~al.}}{{Chen, Duan, Houthooft, Schulman, Sutskever, and Abbeel}}}
\bibcite{goodfellow2014generative}{{5}{2014}{{Goodfellow et~al.}}{{Goodfellow, Pouget-Abadie, Mirza, Xu, Warde-Farley, Ozair, Courville, and Bengio}}}
\bibcite{hinton2006reducing}{{6}{2006}{{Hinton and Salakhutdinov}}{{}}}
\bibcite{kingma2013auto}{{7}{2013}{{Kingma and Welling}}{{}}}
\bibcite{kurakin2016adversarial}{{8}{2016}{{Kurakin et~al.}}{{Kurakin, Goodfellow, and Bengio}}}
\bibcite{lewis1982using}{{9}{1982}{{Lewis}}{{}}}
\bibcite{lipton2018mythos}{{10}{2018}{{Lipton}}{{}}}
\bibcite{2016:lungberg}{{11}{2016}{{Lundberg and Lee}}{{}}}
\bibcite{miller2019explanation}{{12}{2019}{{Miller}}{{}}}
\bibcite{olah2017feature}{{13}{2017}{{Olah et~al.}}{{Olah, Mordvintsev, and Schubert}}}
\bibcite{2016:Ribeioro}{{14}{2016}{{Ribeiro et~al.}}{{Ribeiro, Singh, and Guestrin}}}
\bibcite{ross2017right}{{15}{2017}{{Ross et~al.}}{{Ross, Hughes, and Doshi-Velez}}}
\bibcite{2007:zaidan}{{16}{2007}{{Zaidan et~al.}}{{Zaidan, Eisner, and Piatko}}}
\bibcite{zhou2018diverse}{{17}{2018}{{Zhou et~al.}}{{Zhou, Wang, and Bilmes}}}
\gdef \@abspage@last{12}
